<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Balbonario on</title><link>https://balbonario.github.io/</link><description>Recent content in Balbonario on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://balbonario.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Classical Machine Learning</title><link>https://balbonario.github.io/indices/classical-machine-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://balbonario.github.io/indices/classical-machine-learning/</guid><description>Classical Machine Learning refers to the more ancient part of machine learning, which has many relations with statistics, and mainly deals with the problem of Function Approximation via Convex Optimization of some basic models.</description></item><item><title>Function Approximation</title><link>https://balbonario.github.io/machine-learning/function-approximation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://balbonario.github.io/machine-learning/function-approximation/</guid><description>The setting of Function Approximation is the following: suppose you are given two spaces $X$ and $Y$, which model respectively the &amp;ldquo;independent variable&amp;rdquo; and the &amp;ldquo;dependent variable&amp;rdquo; or, more clearly, $X$ is the variable you can observe (such as concentrations of various molecules in blood) and $Y$ is the variable you are interested in predicting (such as the possibility of a stroke to that person).</description></item><item><title>Hastie, Tibshirani, Friedman - The Elements of Statistical Learning</title><link>https://balbonario.github.io/references/hastie-tibshirani-friedman-the-elements-of-statistical-learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://balbonario.github.io/references/hastie-tibshirani-friedman-the-elements-of-statistical-learning/</guid><description>#todo This is a well-known introductory book in the field of Classical Machine Learning.</description></item><item><title>K-Nearest Neighbours</title><link>https://balbonario.github.io/machine-learning/k-nearest-neighbours/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://balbonario.github.io/machine-learning/k-nearest-neighbours/</guid><description>$k$-nearest neighbours is a Function Approximation algorithm which assumes that the function to approximate is locally constant, and thus approximates the output variable $\hat y$ with a mean of the $k$ nearest neighbours, i.</description></item><item><title>Linear Regression</title><link>https://balbonario.github.io/machine-learning/linear-regression/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://balbonario.github.io/machine-learning/linear-regression/</guid><description>Linear regression is a Function Approximation algorithm which assumes that your function is linear, i.e. $\hat Y = \beta X$ where $X \in \mathbb{R}^{p \times n}, \hat Y \in \mathbb{R}^{m \times n}, \beta \in \mathbb{R}^{m \times p}$, and $\beta$ is the matrix of coefficients to be fit.</description></item><item><title>Loss Function</title><link>https://balbonario.github.io/machine-learning/loss-function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://balbonario.github.io/machine-learning/loss-function/</guid><description>#todo How to choose a loss function?</description></item><item><title>Mean Squared Error</title><link>https://balbonario.github.io/machine-learning/mean-squared-error/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://balbonario.github.io/machine-learning/mean-squared-error/</guid><description>The mean squared error is a Loss Function typically used in classical Function Approximation. Given $n$ datapoints $(x_i, y_i)$ and relative predictions made by a learning algorithm $\hat y_i = f(x_i)$, the loss function is defined as: $$\mathcal{L}(f) := \frac1n \sum_{i = 1}^n \left(y_i - f(x_i)\right)^2.</description></item></channel></rss>